from __future__ import annotations

import argparse
from abc import ABC, abstractmethod
from typing import List

import numpy as np
import torch
import torchvision.transforms as transforms
from PIL import Image
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from inference_module import DenseSwAVModule, InferenceInterface


class EmbeddingVisualizerInterface():
    """
    """
    def __init__(self, emb_vizualizer: EmbeddingVisualizer):
        """
        """
        self._emb_vizualizer = emb_vizualizer

    @property
    def emb_visualizer(self) -> EmbeddingVisualizer:
        return self._emb_vizualizer

    @emb_visualizer.setter
    def emb_visualizer(self, emb_visualizer: EmbeddingVisualizer) -> None:
        self._emb_vizualizer = emb_visualizer

    def generate(self, input: torch.Tensor) -> torch.tensor:
        """
        """
        output = self._emb_vizualizer.generate(input)
        return output

    def comp_pca_mapping(self, img_list: List) -> PCA:
        """
        """
        pca = self._emb_vizualizer.comp_pca_mapping(img_list)
        return pca

    def comp_tsne_mapping(self, img_list: List):
        raise NotImplementedError


class EmbeddingVisualizer(ABC):
    """
    Embedding visualizer interface implements common functionality and provides
    abstract methods to be implemented by concrete embedding visualizers.
    """
    def __init__(self,
                 config_path: str,
                 default_config_path: str,
                 checkpoint_path: str,
                 output_type: str,
                 use_gpu: bool,
                 emb_type: str = "pca",
                 pca: PCA = None,
                 viz_thres: float = 0.):
        """
        Initializes a common VISSL model inference module and image
        transformation pipelines.
        """
        # Configuration parameters
        self.config_path = config_path
        self.default_config_path = default_config_path
        self.checkpoint_path = checkpoint_path
        self.output_type = output_type
        self.use_gpu = use_gpu
        self.emb_type = emb_type
        self.viz_thres = viz_thres
        # Embedding mappings
        self.pca = pca

        # Setup common inference module
        self.vissl_module = InferenceInterface(
            DenseSwAVModule(
                config_path,
                default_config_path,
                checkpoint_path,
                output_type,
                use_gpu=True,
            ))

        self.pipeline = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225])
        ])

    def convert_img(self, img: Image) -> torch.Tensor:
        """
        Converts an image into the default torch.Tensor format.
        """
        input = self.pipeline(img)
        if self.use_gpu:
            input = input.cuda()
        input = input.unsqueeze(0)
        # Transform into batch
        # input = input.repeat(2, 1, 1, 1) TODO delete?
        return input

    @abstractmethod
    def generate(self, img: Image) -> np.array:
        """
        Implement function that generates and outputs an embedding map for a
        given image using the initialized common inference module.

        Args:
            img (PIL.Image): RGB image with height H and width W.
        Returns:
            emb_map (np.array): Array with dim (D, H, W).
        """
        pass

    @abstractmethod
    def comp_pca_mapping(self, img_list: List) -> PCA:
        """
        """
        pass

    def run_model(self, img: Image) -> List:
        """
        Returns a list of output tensors generated by the model from the input
        image.
        """
        x = self.convert_img(img)
        out = self.vissl_module.forward(x)
        return out

    def transform_pca(self, out_vecs: torch.Tensor) -> np.array:
        """
        """
        out_vecs = out_vecs.cpu().numpy()
        if self.pca is None:
            raise Exception("No PCA transformation specified")
        out_vecs = self.pca.transform(out_vecs)
        return out_vecs

    def transform_tsne(self, out_vecs: torch.Tensor) -> np.array:
        """
        """
        raise NotImplementedError

    @staticmethod
    def get_embedding_vecs(output: List) -> torch.Tensor:
        return output[0]

    @staticmethod
    def get_score_vecs(output: List) -> torch.Tensor:
        return output[1]


class FuzzyEmbeddingVisualizer(EmbeddingVisualizer):
    """
    Visualizer for fuzzy vector embeddings which have not been tokenized.
    """
    def __init__(self,
                 config_path: str,
                 default_config_path: str,
                 checkpoint_path: str,
                 output_type: str,
                 use_gpu: bool,
                 emb_type: str = "pca",
                 pca: PCA = None,
                 viz_thres: float = 0.):
        super().__init__(config_path, default_config_path, checkpoint_path,
                         output_type, use_gpu, emb_type, pca, viz_thres)

    def generate(self, img: Image) -> np.array:
        """
        Args:
            img (PIL.Image): RGB image with height H and width W.
        Returns:
            emb_map (np.array): Array with dim (D, H, W).
        """
        return self.comp_fuzzy_rgb_embedding_map(img)

    def comp_fuzzy_embedding_map(self, img: Image) -> np.array:
        """
        """
        out = self.run_model(img)
        out = self.get_embedding_vecs(out)
        if self.emb_type == "pca":
            out = self.transform_pca(out)
        elif self.emb_type == "tsne":
            out = self.transform_tsne(out)
        else:
            raise ValueError(f"Undefined embedding type ({type})")

        # Rearrange row vectors to embedding map
        w, h = img.size
        out = np.reshape(out, (h, w, -1))

        return out

    def comp_fuzzy_rgb_embedding_map(self, img: Image) -> np.array:
        """
        """
        out = self.comp_fuzzy_embedding_map(img)
        # Convert to normalized RGB image integer values
        out = (out - np.min(out)) / (np.max(out) - np.min(out))
        out *= 255
        out = out.astype(int)
        return out

    def comp_pca_mapping(self, img_list: List) -> PCA:
        """
        Computes a PCA mapping based on a list of images and stores it as a
        member, as well as returns the mapping for possible save to disk.
        """
        embs = []
        for img in img_list:
            output = self.run_model(img)
            output = self.get_embedding_vecs(output)
            output = output.cpu()
            embs.append(output)
        embs = torch.cat(embs)
        embs = embs.cpu()
        self.pca = PCA(n_components=3)
        self.pca.fit(embs)
        return self.pca


class SymbolicEmbeddingVisualizer(EmbeddingVisualizer):
    """
    Visualizer for symbolic vector embeddings.
    """
    def __init__(self,
                 config_path: str,
                 default_config_path: str,
                 checkpoint_path: str,
                 output_type: str,
                 use_gpu: bool,
                 emb_type: str = "pca",
                 pca: PCA = None,
                 viz_thres: float = 0.):
        super().__init__(config_path, default_config_path, checkpoint_path,
                         output_type, use_gpu, emb_type, pca, viz_thres)

    def generate(self, img: Image) -> np.array:
        """
        Args:
            img (PIL.Image): RGB image with height H and width W.
        Returns:
            emb_map (np.array): Array with dim (D, H, W).
        """
        return self.comp_symbolic_rgb_embedding_map(img)

    def comp_symbolic_rgb_embedding_map(self, img: Image) -> np.array:
        """
        """
        out, clear_symbol_mask = self.comp_symbolic_embedding_map(img)
        # Convert to normalized RGB image integer values
        out = (out - np.min(out)) / (np.max(out) - np.min(out))
        out *= 255
        out = out.astype(int)

        # Mask out unconfident symbols
        out = out * clear_symbol_mask

        return out

    def comp_symbolic_embedding_map(self, img: Image) -> np.array:
        """
        """
        out = self.run_model(img)
        out = self.get_score_vecs(out).cpu()
        out, clear_symbol_mask = self.emb2symbol(out)
        if self.emb_type == "pca":
            out = self.transform_pca(out)
        elif self.emb_type == "tsne":
            out = self.transform_tsne(out)
        else:
            raise ValueError(f"Undefined embedding type ({type})")

        # Rearrange row vectors to embedding map
        w, h = img.size
        out = np.reshape(out, (h, w, -1))
        clear_symbol_mask = np.reshape(clear_symbol_mask.numpy(), (h, w, -1))

        return out, clear_symbol_mask

    def emb2symbol(self, score_mat: torch.Tensor) -> torch.tensor:
        """
        """
        with torch.no_grad():
            cluster_mat = self.vissl_module.get_clusters().cpu()
            cluster_mat = cluster_mat.T  # dim (D, K)

            sim_val, sim_idx = torch.max(score_mat, dim=1)

            symbol_mat = torch.index_select(cluster_mat, 1, sim_idx).T

            # Clear symbol mask
            D, K = cluster_mat.shape
            clear_symbol_mask = torch.ones(sim_idx.shape, dtype=torch.bool)
            clear_symbol_mask[sim_val < self.viz_thres] = False

        return symbol_mat, clear_symbol_mask

    def comp_pca_mapping(self, img_list: List) -> PCA:
        """
        Computes a PCA mapping based on a list of images and stores it as a
        member, as well as returns the mapping for possible save to disk.
        """
        embs = []
        for img in img_list:
            output = self.run_model(img)
            cluster_score_mat = self.get_score_vecs(output).cpu()

            # Discretize embeddings to symbols
            output, _ = self.emb2symbol(cluster_score_mat)
            output_ = output.cpu().clone().detach()

            embs.append(output_)

        embs = torch.cat(embs)
        self.pca = PCA(n_components=3)
        self.pca.fit(embs)
        return self.pca


if __name__ == "__main__":

    parser = argparse.ArgumentParser()
    parser.add_argument("img_path", type=str)
    parser.add_argument("config_path", type=str, help="Path to config file.")
    parser.add_argument("checkpoint_path",
                        type=str,
                        help="Path to checkpoint file.")
    parser.add_argument("output_type",
                        type=str,
                        help="Output type choice (viz_emb, backbone).")
    parser.add_argument("--default-config-path",
                        type=str,
                        default="vissl/config/defaults.yaml",
                        help="Path to default config file")
    args = parser.parse_args()

    img_path = args.img_path
    config_path = args.config_path
    checkpoint_path = args.checkpoint_path
    output_type = args.output_type
    default_config_path = args.default_config_path

    # 0. PCA mapping
    # pca = pickle.load(open("pca.pkl", "rb"))
    pca = None

    # 1. Setup embedding visualizer module
    emb_viz_module = EmbeddingVisualizerInterface(
        FuzzyEmbeddingVisualizer(config_path,
                                 default_config_path,
                                 checkpoint_path,
                                 output_type,
                                 use_gpu=True,
                                 pca=pca))

    # Optional: Compute common PCA mapping
    # import glob
    # img_paths = glob.glob("/home/robin/projects/vissl/exp_imgs/*.png")
    # imgs = []
    # for img_path in img_paths:
    #     img = Image.open(img_path).convert("RGB")
    #     imgs.append(img)
    # pca = emb_viz_module.comp_pca_mapping(imgs)
    # pickle.dump(pca, open("pca.pkl", "wb"))
    # exit()

    # 2. Read image
    img = Image.open(img_path).convert("RGB")

    # 3. Run embedding visualizer
    _ = emb_viz_module.comp_pca_mapping([img])
    emb_viz = emb_viz_module.generate(img)
